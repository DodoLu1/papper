{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義Transformer模型的結構："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 3\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m num_tokens \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model \u001b[39m=\u001b[39m transformer_model(num_tokens, num_classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_test, y_test), epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 3\u001b[0m in \u001b[0;36mtransformer_model\u001b[1;34m(num_tokens, num_classes, max_len, d_model, num_heads, ff_dim, dropout)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m LayerNormalization()(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m query \u001b[39m=\u001b[39m key \u001b[39m=\u001b[39m value \u001b[39m=\u001b[39m x  \u001b[39m# 將輸入改成一個列表，包含三個相同的 Tensor\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x \u001b[39m=\u001b[39m MultiHeadAttention(num_heads, d_model)([query, key, value])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m Dropout(dropout)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x \u001b[39m=\u001b[39m LayerNormalization()(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "def transformer_model(num_tokens, num_classes, max_len=512, d_model=256, num_heads=8, ff_dim=1024, dropout=0.1):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(num_tokens, d_model)(inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    # Encoder\n",
    "    for i in range(2):\n",
    "        x = LayerNormalization()(x)\n",
    "        query = key = value = x  # 將輸入改成一個列表，包含三個相同的 Tensor\n",
    "        print(x)\n",
    "        x = MultiHeadAttention(num_heads, d_model)([query, key, value])\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = LayerNormalization()(x)\n",
    "        x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # Classification\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "# 讀取數據集\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "max_len = 512\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# 建立並訓練模型\n",
    "num_tokens = 10000\n",
    "num_classes = 2\n",
    "model = transformer_model(num_tokens, num_classes)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model(num_tokens, num_classes, max_len=512, d_model=256, num_heads=8, ff_dim=1024, dropout=0.1):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    x = Embedding(num_tokens, d_model)(inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    # Encoder\n",
    "    for i in range(2):\n",
    "        x = LayerNormalization()(x)\n",
    "        query = key = value = x  # 將輸入改成一個列表，包含三個相同的 Tensor\n",
    "        x = MultiHeadAttention(num_heads, d_model)([query, key, value])\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = LayerNormalization()(x)\n",
    "        x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # Classification\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用定義的模型進行訓練："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 6\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m num_tokens \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m transformer_model(num_tokens, num_classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_test, y_test), epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 6\u001b[0m in \u001b[0;36mtransformer_model\u001b[1;34m(num_tokens, num_classes, max_len, d_model, num_heads, ff_dim, dropout)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m LayerNormalization()(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m query \u001b[39m=\u001b[39m key \u001b[39m=\u001b[39m value \u001b[39m=\u001b[39m x  \u001b[39m# 將輸入改成一個列表，包含三個相同的 Tensor\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m x \u001b[39m=\u001b[39m MultiHeadAttention(num_heads, d_model)([query, key, value])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m Dropout(dropout)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x \u001b[39m=\u001b[39m LayerNormalization()(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "# 讀取數據集\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "max_len = 512\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# 建立並訓練模型\n",
    "num_tokens = 10000\n",
    "num_classes = 2\n",
    "model = transformer_model(num_tokens, num_classes)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_tokens \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m transformer_model(num_tokens, num_classes)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_test, y_test), epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\DodoLu\\Desktop\\paper\\openpose\\python\\Transformer.ipynb 儲存格 6\u001b[0m in \u001b[0;36mtransformer_model\u001b[1;34m(num_tokens, num_classes, max_len, d_model, num_heads, ff_dim, dropout)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x \u001b[39m=\u001b[39m LayerNormalization()(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m MultiHeadAttention(num_heads, d_model)([x, x])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x \u001b[39m=\u001b[39m Dropout(dropout)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DodoLu/Desktop/paper/openpose/python/Transformer.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m LayerNormalization()(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
